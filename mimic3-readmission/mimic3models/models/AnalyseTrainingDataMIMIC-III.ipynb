{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import metrics\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import mimic3models.metrics as m\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hiplot as hip\n",
    "import re\n",
    "\n",
    "from DataLoader import LoadDataSets\n",
    "from lstm_cnn import LSTM_CNN4\n",
    "from lstm_cnn import trainer, evaluate, calcMetrics, plotLoss, plotAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA RNN and LSTM\n",
    "#In some versions of CUDA, RNNs and LSTM networks may have non-deterministic behavior. See torch.nn.RNN() and torch.nn.LSTM() for details and workarounds.\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "def randseed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "randseed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-dealer",
   "metadata": {},
   "source": [
    "# MIMIC-III and MIMIC-IV test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del train_data\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del test_data\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del val_data\n",
    "except:\n",
    "    pass\n",
    "\n",
    "already_loaded = False\n",
    "mimic4 = False\n",
    "\n",
    "dataloader_train, dataloader_val, dataloader_test = LoadDataSets(batch_size=64,mimic4=mimic4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-worcester",
   "metadata": {},
   "source": [
    "# Get data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAnalysisData(listoffiles):\n",
    "    repat = r\"/model__(\\d+)_(\\d+)_(\\d+)_(.*)_(\\d\\.\\d)-(\\d\\.\\d)-(\\d\\.\\d)__epoch-(\\d+)_loss-(.*)_acc-(.*)_auc-(.*).pth\"\n",
    "\n",
    "    allaucs = []\n",
    "    prepfordf = []\n",
    "\n",
    "    for file in listoffiles:\n",
    "        r = re.compile(repat)\n",
    "        p = re.findall(r,file)\n",
    "\n",
    "        repat2 = r\"/model__(.*)__\"\n",
    "        r = re.compile(repat2)\n",
    "        filekey = re.findall(r,file)[0]\n",
    "        _, hidden_dim, lstm_layers, lr, dropout, dropout_w, dropout_conv, epoch, loss, acc, auc  = [float(p) for p in list(p[0])]\n",
    "        hidden_dim = int(hidden_dim)\n",
    "        lstm_layers = int(lstm_layers)\n",
    "        epoch = int(epoch)\n",
    "        #o = [hidden_dim, lstm_layers, lr, dropout, dropout_w, dropout_conv]\n",
    "        #aucrec = [auc,o,filekey]\n",
    "        #allaucs.append(aucrec)\n",
    "        prepfordf.append([hidden_dim, lstm_layers, lr, dropout, dropout_w, dropout_conv, epoch, loss, acc, auc, filekey])\n",
    "    \n",
    "    a = pd.DataFrame(prepfordf, columns=[\"hidden_dim\", \"lstm_layers\", \"lr\", \"dropout\", \"dropout_w\", \"dropout_conv\", \"epoch\", \"loss\", \"acc\", \"auc\",\"filekey\"])\n",
    "    #b = a.groupby([\"hidden_dim\", \"lstm_layers\", \"lr\", \"dropout\", \"dropout_w\", \"dropout_conv\"], sort=True)['epoch'].max()\n",
    "    idx = a.groupby([\"hidden_dim\", \"lstm_layers\", \"lr\", \"dropout\", \"dropout_w\", \"dropout_conv\"])['epoch'].transform(max) == a['epoch']\n",
    "    df = a[idx]\n",
    "    \n",
    "    # convert to list again\n",
    "    allaucs = []\n",
    "    for index, row in df.iterrows():\n",
    "        auc = row['auc']\n",
    "        filekey = row['filekey']\n",
    "        o = [int(row['hidden_dim']), int(row['lstm_layers']), row['lr'], row['dropout'], row['dropout_w'], row['dropout_conv']]\n",
    "        aucrec = [auc,o,filekey]\n",
    "        allaucs.append(aucrec)\n",
    "        \n",
    "    allaucs.sort(key=lambda tup: tup[0])\n",
    "    print(len(allaucs))\n",
    "\n",
    "    maxrecords = 2000\n",
    "    topdata = allaucs[-maxrecords:]\n",
    "\n",
    "    print(f\"From {len(allaucs)} records we will use {len(topdata)} for data analysis.\")\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_test_auc = 0.0\n",
    "    dataforhiplot = []\n",
    "\n",
    "    for idx, auc in enumerate(topdata):\n",
    "        print(idx, \" -> \", auc[2],auc[0],auc[1][:6])\n",
    "        (hidden_dim, lstm_layers, lr, dropout, dropout_w, dropout_conv) = auc[1][:6]\n",
    "        pattern = auc[2]\n",
    "        filename = glob.glob(f'model_archive/20210325_mimic3_gridsearch/*{pattern}*.pth')[-1]\n",
    "\n",
    "        # define threshold\n",
    "        threshold = 0.5\n",
    "        logit_threshold = torch.tensor (threshold / (1 - threshold)).log()\n",
    "        number_epochs=6\n",
    "\n",
    "        model = LSTM_CNN4(hidden_dim=hidden_dim, lstm_layers=lstm_layers, dropout=0.5, dropout_w=0.5, dropout_conv=0.5)\n",
    "        model.to(device)\n",
    "        model.load_state_dict(torch.load(filename))\n",
    "        model.eval()\n",
    "\n",
    "        # validation of the model\n",
    "        outputs, targets = evaluate(dataloader_test, model, device)\n",
    "\n",
    "        #y_pred = torch.sigmoid(torch.tensor(outputs))\n",
    "        outputs = torch.tensor(outputs)\n",
    "\n",
    "        #predicted_vals = y_pred > logit_threshold\n",
    "        #o = np.where(outputs.clone().detach().numpy() > 0.5, 1., 0.)\n",
    "        o = outputs > logit_threshold\n",
    "        accuracy = metrics.accuracy_score(targets, o)\n",
    "        #print(metrics.classification_report(targets, o))\n",
    "        #l = np.asarray(error)\n",
    "        l = nn.BCEWithLogitsLoss()(outputs, torch.tensor(targets).detach().view(-1,1))\n",
    "        #val_loss_values.append(l)\n",
    "        #print(f\"Epochs Val: {number_epochs}, Accuracy Score = {accuracy}, Loss = {l.mean()}\")\n",
    "        #print(\"-\"*20)\n",
    "        #m.print_metrics_binary(targets, outputs.reshape(-1,))\n",
    "\n",
    "        fpr, tpr, threshold = metrics.roc_curve(targets, outputs)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        print(\"ROC AUC = \", roc_auc)\n",
    "\n",
    "        dataforhiplot.append({\"hidden_dim\": hidden_dim, \"lstm_layers\": lstm_layers, \"lr\": lr,\n",
    "         \"dropout\": dropout, \"dropout_w\": dropout_w, \"dropout_conv\": dropout_conv,\n",
    "         \"val_auc\": auc[0], \"test_auc\": roc_auc})\n",
    "\n",
    "        if roc_auc > best_test_auc:\n",
    "            print(\"***** best...\")\n",
    "            best = auc\n",
    "            best_test_auc = roc_auc\n",
    "    \n",
    "    # save hiplot data\n",
    "    pickle.dump(dataforhiplot, open(f\"dataforhiplot_mimic3_all.pkl\", \"wb\" ) )\n",
    "\n",
    "    return dataforhiplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"model_archive/20210325_mimic3_gridsearch\"\n",
    "\n",
    "if mimic4:\n",
    "    try:\n",
    "        dataforhiplot = pickle.load(open(f\"dataforhiplot_mimic4_all.pkl\", \"rb\" ))\n",
    "    except:\n",
    "        listoffiles = glob.glob(F\"{model_file_path}/model__*.pth\")\n",
    "        dataforhiplot = computeAnalysisData(listoffiles)\n",
    "else:\n",
    "    try:\n",
    "        dataforhiplot = pickle.load(open(f\"dataforhiplot_mimic3_all.pkl\", \"rb\" ))\n",
    "    except:\n",
    "        listoffiles = glob.glob(F\"{model_file_path}/model__*.pth\")\n",
    "        dataforhiplot = computeAnalysisData(listoffiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-stick",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MIMIC-III\n",
    "hip.Experiment.from_iterable(dataforhiplot).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-flower",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
